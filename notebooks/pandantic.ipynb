{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3f9b92d-3d09-4096-a73b-ff517d24da60",
   "metadata": {},
   "source": [
    "## pandantic experiments\n",
    "\n",
    "\"simple\" goal: pydantic schema for generating a dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c45ae309-11ef-4997-b26c-26d1d571f58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from inspect import getfullargspec\n",
    "import pandas as pd\n",
    "import typing\n",
    "import json\n",
    "from pydantic import BaseModel, create_model, validator, Field, ValidationError\n",
    "import numpy as np\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97099fd5-140f-4ad0-9189-676426f76ed4",
   "metadata": {},
   "source": [
    "first, check out the instantiation args for a dataframe:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef529e78-fe44-4144-ba06-6571885df8ad",
   "metadata": {},
   "source": [
    "pd.DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ba25911-4303-490c-95bb-e6df540d29b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Axes | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Axes | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Dtype | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Two-dimensional, size-mutable, potentially heterogeneous tabular data.\n",
       "\n",
       "Data structure also contains labeled axes (rows and columns).\n",
       "Arithmetic operations align on both row and column labels. Can be\n",
       "thought of as a dict-like container for Series objects. The primary\n",
       "pandas data structure.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "data : ndarray (structured or homogeneous), Iterable, dict, or DataFrame\n",
       "    Dict can contain Series, arrays, constants, dataclass or list-like objects. If\n",
       "    data is a dict, column order follows insertion-order.\n",
       "\n",
       "    .. versionchanged:: 0.25.0\n",
       "       If data is a list of dicts, column order follows insertion-order.\n",
       "\n",
       "index : Index or array-like\n",
       "    Index to use for resulting frame. Will default to RangeIndex if\n",
       "    no indexing information part of input data and no index provided.\n",
       "columns : Index or array-like\n",
       "    Column labels to use for resulting frame when data does not have them,\n",
       "    defaulting to RangeIndex(0, 1, 2, ..., n). If data contains column labels,\n",
       "    will perform column selection instead.\n",
       "dtype : dtype, default None\n",
       "    Data type to force. Only a single dtype is allowed. If None, infer.\n",
       "copy : bool or None, default None\n",
       "    Copy data from inputs.\n",
       "    For dict data, the default of None behaves like ``copy=True``.  For DataFrame\n",
       "    or 2d ndarray input, the default of None behaves like ``copy=False``.\n",
       "\n",
       "    .. versionchanged:: 1.3.0\n",
       "\n",
       "See Also\n",
       "--------\n",
       "DataFrame.from_records : Constructor from tuples, also record arrays.\n",
       "DataFrame.from_dict : From dicts of Series, arrays, or dicts.\n",
       "read_csv : Read a comma-separated values (csv) file into DataFrame.\n",
       "read_table : Read general delimited file into DataFrame.\n",
       "read_clipboard : Read text from clipboard into DataFrame.\n",
       "\n",
       "Examples\n",
       "--------\n",
       "Constructing DataFrame from a dictionary.\n",
       "\n",
       ">>> d = {'col1': [1, 2], 'col2': [3, 4]}\n",
       ">>> df = pd.DataFrame(data=d)\n",
       ">>> df\n",
       "   col1  col2\n",
       "0     1     3\n",
       "1     2     4\n",
       "\n",
       "Notice that the inferred dtype is int64.\n",
       "\n",
       ">>> df.dtypes\n",
       "col1    int64\n",
       "col2    int64\n",
       "dtype: object\n",
       "\n",
       "To enforce a single dtype:\n",
       "\n",
       ">>> df = pd.DataFrame(data=d, dtype=np.int8)\n",
       ">>> df.dtypes\n",
       "col1    int8\n",
       "col2    int8\n",
       "dtype: object\n",
       "\n",
       "Constructing DataFrame from numpy ndarray:\n",
       "\n",
       ">>> df2 = pd.DataFrame(np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]),\n",
       "...                    columns=['a', 'b', 'c'])\n",
       ">>> df2\n",
       "   a  b  c\n",
       "0  1  2  3\n",
       "1  4  5  6\n",
       "2  7  8  9\n",
       "\n",
       "Constructing DataFrame from a numpy ndarray that has labeled columns:\n",
       "\n",
       ">>> data = np.array([(1, 2, 3), (4, 5, 6), (7, 8, 9)],\n",
       "...                 dtype=[(\"a\", \"i4\"), (\"b\", \"i4\"), (\"c\", \"i4\")])\n",
       ">>> df3 = pd.DataFrame(data, columns=['c', 'a'])\n",
       "...\n",
       ">>> df3\n",
       "   c  a\n",
       "0  3  1\n",
       "1  6  4\n",
       "2  9  7\n",
       "\n",
       "Constructing DataFrame from dataclass:\n",
       "\n",
       ">>> from dataclasses import make_dataclass\n",
       ">>> Point = make_dataclass(\"Point\", [(\"x\", int), (\"y\", int)])\n",
       ">>> pd.DataFrame([Point(0, 0), Point(0, 3), Point(2, 3)])\n",
       "   x  y\n",
       "0  0  0\n",
       "1  0  3\n",
       "2  2  3\n",
       "\u001b[0;31mFile:\u001b[0m           ~/.pyenv/versions/3.9.1/envs/pandantic/lib/python3.9/site-packages/pandas/core/frame.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     SubclassedDataFrame\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e49727-fe2d-411c-81b9-3ab4dd92bcf5",
   "metadata": {},
   "source": [
    "So some complexity here... \n",
    "1. the `data` arg can be many things and is not explicitly typed. it's validated within `DataFrame.__init__()`, but not typed because it can be so many things.\n",
    "2. except for `copy`, the arguments are internal pandas types. We can check out the `Dtypes` and `Axes` types are with:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c818c70-0916-4b24-bd7f-62d821e221b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "typing.Collection[typing.Any]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd._typing.Axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ded6f473-9b48-4994-845f-b6ac0ab42291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "typing.Union[ForwardRef('ExtensionDtype'), str, numpy.dtype, typing.Type[typing.Union[str, float, int, complex, bool, object]]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd._typing.Dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47956ad1-451a-4be9-85eb-76c2150d7daf",
   "metadata": {},
   "source": [
    "### initial manual `DataFrameModel`\n",
    "\n",
    "a simple attempt at building a pydantic model. Adding a `dtype` attribute is proving difficult... for now, we'll use a string declaration approach with `Enum`. So let's construct a `DtypeEnum` from a list of strings corresponding to data types that we'll allow. When we get to trying to instantiate a true pandas `DataFrame`, we'll use `eval()` to get an actual type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "239b4717-ad6f-4edb-9c95-a8a50d26d1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed_types = ['int', 'float', 'str', 'complex', 'np.int64', 'np.float64'] # not a complete list...\n",
    "DtypeEnum = Enum(\"DtypeEnum\", dict(zip(allowed_types, allowed_types)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75062e0d-407c-412a-a091-0d1d8a40bc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFrameModel(BaseModel):\n",
    "    data: dict # for simplicity for now, only allow data dict\n",
    "    index: typing.Optional[pd._typing.Axes] = None\n",
    "    columns: typing.Optional[pd._typing.Axes] = None    \n",
    "    dtype: typing.Optional[DtypeEnum] = None\n",
    "    copy_: typing.Optional[bool] = Field(None, alias='copy')\n",
    "    \n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True  ## needed for Axes type        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71d10c87-4db8-40c4-b229-f2ecec8f6828",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataFrameModel.construct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d3a9524-51fc-4f84-9b39-f65b1b97d680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'DataFrameModel',\n",
       " 'type': 'object',\n",
       " 'properties': {'data': {'title': 'Data', 'type': 'object'},\n",
       "  'index': {'title': 'Index'},\n",
       "  'columns': {'title': 'Columns'},\n",
       "  'dtype': {'$ref': '#/definitions/DtypeEnum'},\n",
       "  'copy': {'title': 'Copy', 'type': 'boolean'}},\n",
       " 'required': ['data'],\n",
       " 'definitions': {'DtypeEnum': {'title': 'DtypeEnum',\n",
       "   'description': 'An enumeration.',\n",
       "   'enum': ['int', 'float', 'str', 'complex', 'np.int64', 'np.float64']}}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a91308d-0770-477c-8b0c-7d7b2bf7197e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_schema.json', 'w') as fi:\n",
    "    fi.write(df.schema_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6f96bf1-3597-4a57-99ba-6248ecc5341f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrameModel(data={'a': [1, 2, 3]}, index=None, columns=None, dtype=<DtypeEnum.complex: 'complex'>, copy_=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataFrameModel(data={\"a\":[1,2,3]}, dtype=\"complex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a876b1b-5eb9-4eea-ab1c-836523a1338c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"data\": {\"a\": [1, 2, 3]}, \"index\": null, \"columns\": null, \"dtype\": \"complex\", \"copy_\": null}'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataFrameModel(data={\"a\":[1,2,3]}, dtype=\"complex\").json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0853f9-8124-4fff-b5de-91ad5d8a938a",
   "metadata": {},
   "source": [
    "## instiating a dataframe. \n",
    "\n",
    "Assuming we've used our schema above to write a json to `filled_schema.json`, let's actually instantiate a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "008ae56a-3fe4-4f01-a3f4-2584c7fc9f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_model = DataFrameModel.parse_file('filled_schema.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10df4c8a-3b53-4537-b3a8-9777427bb077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrameModel(data={'col_1': [1, 2, 3, 4], 'col_2': [-1, 20, 30, -20]}, index=None, columns=None, dtype=<DtypeEnum.np.int64: 'np.int64'>, copy_=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976ff53a-e3ca-4d09-9861-9328ce74708d",
   "metadata": {},
   "source": [
    "in the yt analysis schema approach, we attached a `._run` attribute to the pydantic classes. but it may be clearer to have a separate ingestion process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5487a1a1-48d9-4b09-a45b-045e1b6c4c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def instantiate_df(pandantic_model: DataFrameModel) -> pd.DataFrame:\n",
    "    enum_dtype = pandantic_model.dtype # e.g., <DtypeEnum.int: 'int'>\n",
    "    dtype_str = enum_dtype.value # e.g., 'int'\n",
    "    actual_dtype = eval(dtype_str) # e.g., int \n",
    "    return pd.DataFrame(pandantic_model.data, \n",
    "                        index=pandantic_model.index, \n",
    "                        columns=pandantic_model.columns,\n",
    "                        dtype=actual_dtype,\n",
    "                        copy=pandantic_model.copy_\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "138f6071-0a71-4c32-96e8-6af219c91dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = instantiate_df(valid_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6acdbab-9c53-481b-8b46-601178f5d1ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_1</th>\n",
       "      <th>col_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   col_1  col_2\n",
       "0      1     -1\n",
       "1      2     20\n",
       "2      3     30\n",
       "3      4    -20"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c884e6-84a6-4703-8461-0d547a02c795",
   "metadata": {},
   "source": [
    "### combining pydantic and inspect for dynamically generating a model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e6c9f07-2666-45c9-8e34-0bf57e866fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_func = pd.DataFrame\n",
    "df_args = getfullargspec(pd_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e3be283-9c6b-4336-8068-63f4720a5509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'index': 'Axes | None',\n",
       " 'columns': 'Axes | None',\n",
       " 'dtype': 'Dtype | None',\n",
       " 'copy': 'bool | None'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_args.annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1fd38a8-c724-4300-88f2-0a85ed967d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['self', 'data', 'index', 'columns', 'dtype', 'copy']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_args.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87f39de1-0f29-4889-accf-69efa4124f7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None, None, None, None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_args.defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c747eaa9-40cb-4a39-b107-e44beb8281db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic.utils import validate_field_name\n",
    "\n",
    "class BaseDynamic(BaseModel):\n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True          \n",
    "        \n",
    "missing_override_types = {\n",
    "  pd.DataFrame : {'data': dict, 'dtype': DtypeEnum}   \n",
    "}\n",
    "\n",
    "\n",
    "def generate_model_dict(pd_func) -> dict:\n",
    "    f_args = getfullargspec(pd_func)\n",
    "    \n",
    "    # work out how many args, kwargs there are\n",
    "    argnames = f_args.args\n",
    "    print(\"\\nargument names:\")\n",
    "    print(argnames)\n",
    "    if len(argnames)>1 and argnames[0]=='self':        \n",
    "        argnames = argnames[1:]\n",
    "        \n",
    "    n_defaults = len(f_args.defaults)\n",
    "    n_args = len(argnames)\n",
    "    n_arg_only = n_args - n_defaults # number of args \n",
    "    n_kwargs = n_args - n_arg_only # number of kwargs\n",
    "    \n",
    "    default_dict = dict(zip(argnames[n_arg_only:], f_args.defaults))\n",
    "    print(\"\\ndefault values:\")\n",
    "    print(default_dict)\n",
    "    \n",
    "    base_types = ['int', 'bool', 'float', 'None']\n",
    "\n",
    "    # get a dict of the types of each arg\n",
    "    type_dict = {}\n",
    "    for ky, typelist in df_args.annotations.items():\n",
    "\n",
    "        ky_type = None\n",
    "        for type_str in typelist.split(\"|\"):\n",
    "            type_str = type_str.strip()\n",
    "            if hasattr(pd._typing, type_str):\n",
    "                actual_type = getattr(pd._typing, type_str)\n",
    "            elif type_str in base_types:\n",
    "                actual_type = eval(type_str)        \n",
    "            else:\n",
    "                raise NameError(f\"could not find {type_str}\")\n",
    "\n",
    "            if ky_type is None:\n",
    "                ky_type = actual_type\n",
    "            else:\n",
    "                ky_type = typing.Union[ky_type, actual_type]\n",
    "\n",
    "        type_dict[ky] = ky_type\n",
    "        \n",
    "    # set any missing types or overrides\n",
    "    for arg in argnames:\n",
    "        if pd_func in missing_override_types and arg in missing_override_types[pd_func]:\n",
    "            type_dict[arg] = missing_override_types[pd_func][arg]\n",
    "\n",
    "    print(\"\\ntypes:\")\n",
    "    print(type_dict)\n",
    "    \n",
    "    # work out if we need an alias for any fields\n",
    "    arg_aliases = {}\n",
    "    for arg in argnames:\n",
    "        try: \n",
    "            validate_field_name([BaseModel], arg)            \n",
    "        except NameError:\n",
    "            arg_aliases[arg] = arg+\"_\"\n",
    "    print(\"\\nfield aliases:\")\n",
    "    print(arg_aliases)\n",
    "    \n",
    "    # the final dictionary\n",
    "    model_dict = {}\n",
    "    for arg in argnames:\n",
    "        default_value = default_dict[arg]\n",
    "        types = type_dict[arg]\n",
    "        if arg in arg_aliases:\n",
    "            attname = arg_aliases[arg]\n",
    "            field = Field(default=default_value,\n",
    "                          alias=arg_aliases[arg])\n",
    "        else:\n",
    "            attname = arg\n",
    "            field = Field(default=default_value)\n",
    "        model_dict[attname] = (types, field)\n",
    "        \n",
    "    # return a pydantic model\n",
    "    return create_model(pd_func.__name__+\"Model\", **model_dict, __base__=BaseDynamic)                                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4cd373-e865-40cc-98a3-c8ad137aa638",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f18535ca-5c2f-4fcc-b85d-9aa03769b6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "argument names:\n",
      "['self', 'data', 'index', 'columns', 'dtype', 'copy']\n",
      "\n",
      "default values:\n",
      "{'data': None, 'index': None, 'columns': None, 'dtype': None, 'copy': None}\n",
      "\n",
      "types:\n",
      "{'index': typing.Optional[typing.Collection[typing.Any]], 'columns': typing.Optional[typing.Collection[typing.Any]], 'dtype': <enum 'DtypeEnum'>, 'copy': typing.Optional[bool], 'data': <class 'dict'>}\n",
      "\n",
      "field aliases:\n",
      "{'copy': 'copy_'}\n"
     ]
    }
   ],
   "source": [
    "pd_model = generate_model_dict(pd_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "afb3d138-7bf9-460f-a626-30e70afbf555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'DataFrameModel',\n",
       " 'type': 'object',\n",
       " 'properties': {'data': {'title': 'Data', 'type': 'object'},\n",
       "  'index': {'title': 'Index'},\n",
       "  'columns': {'title': 'Columns'},\n",
       "  'dtype': {'$ref': '#/definitions/DtypeEnum'},\n",
       "  'copy_': {'title': 'Copy ', 'type': 'boolean'}},\n",
       " 'definitions': {'DtypeEnum': {'title': 'DtypeEnum',\n",
       "   'description': 'An enumeration.',\n",
       "   'enum': ['int', 'float', 'str', 'complex', 'np.int64', 'np.float64']}}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = pd_model.construct()\n",
    "m.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b8728246-7873-4d44-ab89-c749676bd1b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrameModel(data={'a': [1, 2, 3, 4]}, index=None, columns=None, dtype=<DtypeEnum.np.float64: 'np.float64'>, copy_=None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_model(data={'a':[1,2,3,4]}, dtype='np.float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f414a808-ddb4-48e2-9d3b-0e3809220e5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"data\": {\"a\": [1, 2, 3, 4]}, \"index\": null, \"columns\": null, \"dtype\": \"np.float64\", \"copy_\": null}'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_model(data={'a':[1,2,3,4]}, dtype='np.float64').json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d314904-c443-4122-9f6a-9673176049a2",
   "metadata": {},
   "source": [
    "### semi-automatic ingestion of the pandantic model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fb65f1a2-05f0-4f9e-8063-465a59a5ede3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dtype_ingestor(enum_dtype):    \n",
    "    dtype_str = enum_dtype.value # e.g., 'int'\n",
    "    return eval(dtype_str) # e.g., int \n",
    "    \n",
    "ingestor_funcs = {\n",
    "  pd.DataFrame : {'dtype': dtype_ingestor}   \n",
    "}\n",
    "\n",
    "\n",
    "def auto_instantiator(pd_model, pd_funcname):    \n",
    "    pd_func = getattr(pd, pd_funcname)\n",
    "    f_args = getfullargspec(pd_func)\n",
    "    \n",
    "    # work out how many args, kwargs there are\n",
    "    argnames = f_args.args    \n",
    "    if len(argnames)>1 and argnames[0]=='self':        \n",
    "        argnames = argnames[1:]\n",
    "        \n",
    "    n_defaults = len(f_args.defaults)\n",
    "    n_args = len(argnames)\n",
    "    n_arg_only = n_args - n_defaults # number of args \n",
    "    n_kwargs = n_args - n_arg_only # number of kwargs\n",
    "    \n",
    "    # work out if we need an alias for any fields\n",
    "    arg_aliases = {}\n",
    "    for arg in argnames:\n",
    "        try: \n",
    "            validate_field_name([BaseModel], arg)            \n",
    "        except NameError:\n",
    "            arg_aliases[arg] = arg+\"_\"\n",
    "\n",
    "    # build up the arguments for the pd function\n",
    "    args = []\n",
    "    kwargs = {}\n",
    "    for iarg, arg in enumerate(argnames):\n",
    "        \n",
    "        if arg in arg_aliases:\n",
    "            model_argname = arg_aliases[arg]\n",
    "        else:\n",
    "            model_argname = arg\n",
    "        \n",
    "        argval = getattr(pd_model, model_argname)\n",
    "        if arg in ingestor_funcs[pd_func]:\n",
    "            argval = ingestor_funcs[pd_func][arg](argval)\n",
    "                    \n",
    "        if iarg < n_arg_only:\n",
    "            args.append(argval)\n",
    "        else:\n",
    "            kwargs[arg] = argval\n",
    "            \n",
    "    return pd_func(*args, **kwargs)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9130af0e-b4dc-45cb-9952-efc9361bb48e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"data\": {\"a\": [1, 2, 3, 4]}, \"index\": null, \"columns\": null, \"dtype\": \"np.float64\", \"copy_\": null}'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_json = pd_model(data={'a':[1,2,3,4]}, dtype='np.float64').json()\n",
    "model_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e61b725b-5493-480b-96de-3b6bbcfeb163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrameModel(data={'a': [1, 2, 3, 4]}, index=None, columns=None, dtype=<DtypeEnum.np.float64: 'np.float64'>, copy_=None)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model = pd_model.parse_raw(model_json)\n",
    "df_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4c9ef0db-73a3-4edf-99bd-1a97efc222cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = auto_instantiator(df_model, 'DataFrame')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8ff983a9-e367-4243-825f-9a78d21c745e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "77782284-6f17-4c1c-a10b-10358f709369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     a\n",
       "0  1.0\n",
       "1  2.0\n",
       "2  3.0\n",
       "3  4.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
